{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOzymawRPZGVz9WfP0uu+0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-vinamr/rera_construction_pred/blob/main/Streamlined_5th_floor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1e6Rub-Eg3R"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    # Load the dataset\n",
        "    data = pd.read_csv(file_path)\n",
        "    return data"
      ],
      "metadata": {
        "id": "8XjhctqIXlkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(data):\n",
        "    # Convert date columns to datetime objects\n",
        "    data['actual_commencement_date'] = pd.to_datetime(data['actual_commencement_date'], errors='coerce')\n",
        "    data['estimated_finish_date'] = pd.to_datetime(data['estimated_finish_date'], errors='coerce')\n",
        "\n",
        "    # Calculate derived columns\n",
        "    current_date = datetime.now()\n",
        "    data['duration_since_commencement'] = (current_date - data['actual_commencement_date']).dt.days\n",
        "    data['remaining_duration'] = (data['estimated_finish_date'] - current_date).dt.days\n",
        "    data['progress_ratio'] = data['duration_since_commencement'] / data['total_days']\n",
        "    data['current_stage'] = data.apply(determine_status, axis=1)\n",
        "\n",
        "    # Label encoding for 'current_stage' and 'project_state' columns\n",
        "    label_encoder = LabelEncoder()\n",
        "    data['current_stage'] = data['current_stage'].astype(str)\n",
        "    data['current_stage_encoded'] = label_encoder.fit_transform(data['current_stage'])\n",
        "    data['project_state'] = data['project_state'].astype(str)\n",
        "    data['project_state_encoded'] = label_encoder.fit_transform(data['project_state'])\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "Yq9RGDPUXqK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to determine the project status\n",
        "def determine_status(row):\n",
        "    current_date = datetime.now()\n",
        "    if current_date > row['estimated_finish_date']:\n",
        "        return 'completed'\n",
        "    elif current_date >= row['actual_commencement_date']:\n",
        "        return 'running'\n",
        "    else:\n",
        "        return 'upcoming'\n",
        "\n",
        "# Apply the function to create the 'Status' column\n",
        "    data['current_stage'] = data.apply(determine_status, axis=1)\n",
        "    return data"
      ],
      "metadata": {
        "id": "nRH81ttSXu8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_selection(data):\n",
        "    # Select relevant features\n",
        "    numerical_columns = data.select_dtypes(include=['int64', 'float64'])\n",
        "    stage_columns = [\n",
        "    'Cleaning & survey',\n",
        "    'Excavation,leveling & P.C.C for Basement B1',\n",
        "    'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring',\n",
        "    'Slab of B (bottom)',\n",
        "    'Ground Floor slab casting',\n",
        "    '1st floor Columns casting',\n",
        "    '1st Floor slab casting',\n",
        "    '2nd floor Columns casting',\n",
        "    '2nd Floor slab casting',\n",
        "    'Brick work at Basement to Ground Floor',\n",
        "    '3rd floor Columns casting',\n",
        "    '3rd Floor slab casting',\n",
        "    'Brick work at 1st Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at basement- ground floor',\n",
        "    '4th floor Columns casting',\n",
        "    '4th Floor slab casting',\n",
        "    'Brick work at 2nd Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 1st floor',\n",
        "    '5th floor Columns casting',\n",
        "    '5th Floor slab casting',\n",
        "    'Brick work of 3rd to 5th Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor',\n",
        "    'Plastering on outer sides',\n",
        "    'Tiles work',\n",
        "    'Painting and Finishing',\n",
        "    'Plumbing & Sanitary,Electrification Works',\n",
        "    'Doors & Windows Fixing Furniture work'\n",
        "]\n",
        "\n",
        "    # Target variables\n",
        "    X = data[numerical_columns.columns.difference(stage_columns)].drop(columns='total_days')\n",
        "    y_total_days = data['total_days']\n",
        "    y_time_taken_at_each_stage = data[stage_columns]\n",
        "\n",
        "    return X, y_total_days, y_time_taken_at_each_stage"
      ],
      "metadata": {
        "id": "EivyAEotXyid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_evaluate_model(X_train, X_test, y_train, y_test):\n",
        "    # Train and evaluate a Random Forest regression model\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    return model, mse, r2"
      ],
      "metadata": {
        "id": "EXGkQY8jYCww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_relevant_stage_and_columns(row, stage_columns):\n",
        "    current_date = datetime.now()\n",
        "    days_elapsed = row['days_elapsed']\n",
        "    total_days = 0\n",
        "    relevant_stage = None\n",
        "    relevant_columns = []\n",
        "\n",
        "    for stage in stage_columns:\n",
        "        stage_duration = row[stage]  # Days required for the current stage\n",
        "        total_days += stage_duration\n",
        "        if total_days >= days_elapsed:\n",
        "            relevant_stage = stage\n",
        "            relevant_columns = [stage for stage in stage_columns[stage_columns.index(stage):]]\n",
        "            break\n",
        "\n",
        "    return relevant_stage, relevant_columns, total_days"
      ],
      "metadata": {
        "id": "DUmbiL9SYGjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_predictions(row, stage_columns):\n",
        "    if row['current_stage'] == 'completed':\n",
        "        return None  # No predictions for completed projects\n",
        "    elif row['current_stage'] == 'running':\n",
        "        if row['relevant_stage'] is not None:\n",
        "            if row['relevant_stage'] in row['relevant_columns']:\n",
        "                return row[row['relevant_stage']] - (row['days_elapsed'] - row['total_days'])\n",
        "            else:\n",
        "                return None  # Skip stages before the relevant stage\n",
        "        else:\n",
        "            return None  # Skip predictions for running projects with no relevant stage\n",
        "    elif row['current_stage'] == 'upcoming':\n",
        "        return row['total_days']  # Include all stages for upcoming projects"
      ],
      "metadata": {
        "id": "7mRemn7iYK8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3x--JxqYOLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Code**"
      ],
      "metadata": {
        "id": "yJUk7lXFYSCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(file_path):\n",
        "    data = load_data(file_path)\n",
        "    data = preprocess_data(data)\n",
        "\n",
        "    # Determine relevant stage and columns\n",
        "    data['current_stage'] = data.apply(determine_status, axis=1)\n",
        "\n",
        "    X, y_total_days, y_time_taken_at_each_stage = feature_selection(data)\n",
        "\n",
        "    # Split the data for total days\n",
        "    X_train, X_test, y_train_total_days, y_test_total_days = train_test_split(X, y_total_days, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Train and evaluate the model for total days\n",
        "    total_days_model, mse_total_days, r2_total_days = train_evaluate_model(X_train, X_test, y_train_total_days, y_test_total_days)\n",
        "    print(f\"Mean Squared Error (Total Days): {mse_total_days}\")\n",
        "    print(f\"R-squared (Total Days): {r2_total_days}\")\n",
        "\n",
        "    stage_columns = [\n",
        "    'Cleaning & survey',\n",
        "    'Excavation,leveling & P.C.C for Basement B1',\n",
        "    'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring',\n",
        "    'Slab of B (bottom)',\n",
        "    'Ground Floor slab casting',\n",
        "    '1st floor Columns casting',\n",
        "    '1st Floor slab casting',\n",
        "    '2nd floor Columns casting',\n",
        "    '2nd Floor slab casting',\n",
        "    'Brick work at Basement to Ground Floor',\n",
        "    '3rd floor Columns casting',\n",
        "    '3rd Floor slab casting',\n",
        "    'Brick work at 1st Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at basement- ground floor',\n",
        "    '4th floor Columns casting',\n",
        "    '4th Floor slab casting',\n",
        "    'Brick work at 2nd Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 1st floor',\n",
        "    '5th floor Columns casting',\n",
        "    '5th Floor slab casting',\n",
        "    'Brick work of 3rd to 5th Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor',\n",
        "    'Plastering on outer sides',\n",
        "    'Tiles work',\n",
        "    'Painting and Finishing',\n",
        "    'Plumbing & Sanitary,Electrification Works',\n",
        "    'Doors & Windows Fixing Furniture work'\n",
        "]\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train_total_days, y_test_total_days, y_train_time, y_test_time = train_test_split(X, y_total_days, y_time_taken_at_each_stage, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create and train the regression model for time taken at each stage\n",
        "    stage_models = {}\n",
        "    for stage in stage_columns:\n",
        "        stage_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        stage_model.fit(X_train, y_train_time[stage])\n",
        "        stage_models[stage] = stage_model\n",
        "\n",
        "    # Predict time taken at each stage on the test set\n",
        "    y_pred_time = {}\n",
        "    for stage, stage_model in stage_models.items():\n",
        "        y_pred_time[stage] = stage_model.predict(X_test)\n",
        "    current_date = datetime.now()\n",
        "    data['days_elapsed'] = (current_date - data['actual_commencement_date']).dt.days\n",
        "\n",
        "    # Determine relevant stage and columns\n",
        "    data[['relevant_stage', 'relevant_columns', 'total_days']] = data.apply(lambda row: determine_relevant_stage_and_columns(row, stage_columns), axis=1, result_type='expand')\n",
        "\n",
        "    data['relevant_stage'].fillna('Doors & Windows Fixing Furniture work', inplace=True)\n",
        "\n",
        "    # Filter projects based on current_stage\n",
        "    completed_projects = data[data['current_stage'] == 'completed']\n",
        "    running_projects = data[data['current_stage'] == 'running']\n",
        "    upcoming_projects = data[data['current_stage'] == 'upcoming']\n",
        "    # Predict time taken for each project\n",
        "    data['predicted_time_taken'] = data.apply(lambda row: make_predictions(row, stage_columns), axis=1)\n",
        "    data = data.dropna()\n",
        "\n",
        "    # Evaluate the models for time taken at each stage\n",
        "    mse_stage = {}\n",
        "    r2_stage = {}\n",
        "    for stage in stage_columns:\n",
        "        mse_stage[stage] = mean_squared_error(y_test_time[stage], y_pred_time[stage])\n",
        "        r2_stage[stage] = r2_score(y_test_time[stage], y_pred_time[stage])\n",
        "        print(f'Mean Squared Error ({stage}): {mse_stage[stage]}')\n",
        "        print(f'R-squared ({stage}): {r2_stage[stage]}')\n",
        "\n",
        "    # Save the total days model\n",
        "    joblib.dump(total_days_model, 'total_days_model.joblib')\n",
        "\n",
        "    # Save each stage model\n",
        "    for stage, stage_model in stage_models.items():\n",
        "        joblib.dump(stage_model, f'{stage}_model.joblib')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = 'augmented_5_floor.csv'\n",
        "    main(file_path)"
      ],
      "metadata": {
        "id": "jcYB9vUsYUYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "7a4d97a7-7c04-4cbe-815e-9a6a9bfcd947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e0dded9d6723>\u001b[0m in \u001b[0;36m<cell line: 94>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'augmented_5_floor.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-e0dded9d6723>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current_stage'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetermine_status\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_total_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_time_taken_at_each_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Split the data for total days\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7407fedd06ed>\u001b[0m in \u001b[0;36mfeature_selection\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumerical_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'total_days'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0my_total_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_days'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0my_time_taken_at_each_stage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstage_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_total_days\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_time_taken_at_each_stage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6133\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6135\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Excavation,leveling & P.C.C for Basement B1', 'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring', 'Slab of B (bottom)', 'Ground Floor slab casting', '1st floor Columns casting', '1st Floor slab casting', '2nd floor Columns casting', 'Brick work at Basement to Ground Floor', '3rd floor Columns casting', 'Brick work at 1st Floor', '4th floor Columns casting', 'Brick work at 2nd Floor', '5th floor Columns casting', 'Brick work of 3rd to 5th Floor'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new data (replace 'new_data.csv' with the actual file path)\n",
        "new_data = pd.read_csv('new_5_test_file.csv')\n",
        "\n",
        "\n",
        "stage_columns = [\n",
        "    'Cleaning & survey',\n",
        "    'Excavation,leveling & P.C.C for Basement B1',\n",
        "    'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring',\n",
        "    'Slab of B (bottom)',\n",
        "    'Ground Floor slab casting',\n",
        "    '1st floor Columns casting',\n",
        "    '1st Floor slab casting',\n",
        "    '2nd floor Columns casting',\n",
        "    '2nd Floor slab casting',\n",
        "    'Brick work at Basement to Ground Floor',\n",
        "    '3rd floor Columns casting',\n",
        "    '3rd Floor slab casting',\n",
        "    'Brick work at 1st Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at basement- ground floor',\n",
        "    '4th floor Columns casting',\n",
        "    '4th Floor slab casting',\n",
        "    'Brick work at 2nd Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 1st floor',\n",
        "    '5th floor Columns casting',\n",
        "    '5th Floor slab casting',\n",
        "    'Brick work of 3rd to 5th Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor',\n",
        "    'Plastering on outer sides',\n",
        "    'Tiles work',\n",
        "    'Painting and Finishing',\n",
        "    'Plumbing & Sanitary,Electrification Works',\n",
        "    'Doors & Windows Fixing Furniture work'\n",
        "]\n",
        "\n",
        "# Load the total days model\n",
        "total_days_model = joblib.load('total_days_model.joblib')\n",
        "\n",
        "# Load each stage model\n",
        "stage_models = {}\n",
        "for stage in stage_columns:\n",
        "    stage_model = joblib.load(f'{stage}_model.joblib')\n",
        "    stage_models[stage] = stage_model\n",
        "\n",
        "\n",
        "# Converting date columns to datetime objeacts\n",
        "new_data['actual_commencement_date'] = pd.to_datetime(new_data['actual_commencement_date'], errors='coerce')\n",
        "new_data['estimated_finish_date'] = pd.to_datetime(new_data['estimated_finish_date'], errors='coerce')\n",
        "\n",
        "current_date = datetime.now()\n",
        "\n",
        "new_data['total_days'] = (new_data['estimated_finish_date'] - new_data['actual_commencement_date']).dt.days\n",
        "\n",
        "new_data['duration_since_commencement'] = (current_date - new_data['actual_commencement_date']).dt.days\n",
        "new_data['remaining_duration'] = (new_data['estimated_finish_date'] - current_date).dt.days\n",
        "new_data['progress_ratio'] = new_data['duration_since_commencement'] / new_data['total_days']\n",
        "\n",
        "# Define a function to determine the project status\n",
        "def determine_status(row):\n",
        "    if current_date > row['estimated_finish_date']:\n",
        "        return 'completed'\n",
        "    elif current_date >= row['actual_commencement_date']:\n",
        "        return 'running'\n",
        "    else:\n",
        "        return 'upcoming'\n",
        "\n",
        "# Apply the function to create the 'Status' column\n",
        "new_data['current_stage'] = new_data.apply(determine_status, axis=1)\n",
        "\n",
        "# Performing label encoding on the 'current_stage' column\n",
        "label_encoder = LabelEncoder()\n",
        "new_data['current_stage'] =new_data['current_stage'].astype(str) # Converting to string to handle any NaN values left\n",
        "new_data['current_stage_encoded'] = label_encoder.fit_transform(new_data['current_stage'])\n",
        "\n",
        "# Performing label encoding on the 'current_stage' column\n",
        "label_encoder = LabelEncoder()\n",
        "new_data['project_state'] =new_data['project_state'].astype(str) # Converting to string to handle any NaN values left\n",
        "new_data['project_state_encoded'] = label_encoder.fit_transform(new_data['project_state'])\n",
        "\n",
        "new_data['office_no'] = new_data['office_no'].astype(str)\n",
        "\n",
        "# Create an empty DataFrame to store 'new_data' with added columns\n",
        "new_data = new_data.copy()  # Assuming 'new_data' is your original DataFrame\n",
        "\n",
        "# Add stage-related columns and 'total_days' column with NaN values\n",
        "for stage in stage_columns:\n",
        "    new_data[stage] = np.nan\n",
        "\n",
        "new_data['total_days'] = np.nan\n",
        "\n",
        "# Now, 'new_data_with_stages' contains the additional columns with NaN values\n",
        "\n",
        "\n",
        "numerical_columns = new_data.select_dtypes(include=['int64', 'float64'])\n",
        "stage_columns = [\n",
        "    'Cleaning & survey',\n",
        "    'Excavation,leveling & P.C.C for Basement B1',\n",
        "    'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring',\n",
        "    'Slab of B (bottom)',\n",
        "    'Ground Floor slab casting',\n",
        "    '1st floor Columns casting',\n",
        "    '1st Floor slab casting',\n",
        "    '2nd floor Columns casting',\n",
        "    '2nd Floor slab casting',\n",
        "    'Brick work at Basement to Ground Floor',\n",
        "    '3rd floor Columns casting',\n",
        "    '3rd Floor slab casting',\n",
        "    'Brick work at 1st Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at basement- ground floor',\n",
        "    '4th floor Columns casting',\n",
        "    '4th Floor slab casting',\n",
        "    'Brick work at 2nd Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 1st floor',\n",
        "    '5th floor Columns casting',\n",
        "    '5th Floor slab casting',\n",
        "    'Brick work of 3rd to 5th Floor',\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor',\n",
        "    'Plastering on outer sides',\n",
        "    'Tiles work',\n",
        "    'Painting and Finishing',\n",
        "    'Plumbing & Sanitary,Electrification Works',\n",
        "    'Doors & Windows Fixing Furniture work'\n",
        "]\n",
        "\n",
        "# Target variables\n",
        "X_new = new_data[numerical_columns.columns.difference(stage_columns)].drop(columns='total_days')\n",
        "#y_total_days = new_data['total_days']\n",
        "#y_time_taken_at_each_stage = new_data[stage_columns]  # Replace with your actual stage columns\n",
        "\n",
        "new_data['total_days'] = total_days_model.predict(new_data[X_new.columns])\n",
        "\n",
        "for stage in stage_columns:\n",
        "    stage_model = stage_models.get(stage)  # Use get to avoid KeyError\n",
        "    if stage_model:\n",
        "        new_data[stage] = stage_model.predict(new_data[X_new.columns])\n",
        "    else:\n",
        "        # If the stage column isn't in stage_models, fill it with NaN\n",
        "        new_data[stage] = np.nan\n",
        "\n",
        "stage_materials = {\n",
        "    'Cleaning & survey': [],\n",
        "    'Excavation,leveling & P.C.C for Basement B1': ['cement', 'sand', 'aggregates'],\n",
        "    'Raft footing, Column B1, Retaining wall Reinforcement ,Concrete pouring': ['TMT bar', 'cement', 'sand', 'aggregates'],\n",
        "    'Slab of B (bottom)': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Ground Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '1st floor Columns casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '1st Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Brick work at Basement to Ground Floor': ['blocks/bricks', 'cement', 'sand'],\n",
        "    'Electrical concealed, PVC Fitting, plastering at basement- ground floor': ['circuit pipe', 'Cpvc', '&Pvc pipe', 'cement', 'sand'],\n",
        "    '2nd floor Columns casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '2nd Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Brick work at 1st Floor': ['blocks/bricks', 'cement', 'sand'],\n",
        "    'Electrical concealed, PVC Fitting, plastering at 1st floor': ['circuit pipe', 'Cpvc', '&Pvc pipe', 'cement', 'sand'],\n",
        "    '3rd floor Columns casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '3rd Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Brick work at 2nd Floor': ['blocks/bricks', 'cement', 'sand'],\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor': ['cement', 'sand', 'circuit pipe', 'Cpvc', '&Pvc pipe'],\n",
        "    '4th floor Columns casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '4th Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Brick work at 3rd to 5th Floor': ['blocks/bricks', 'cement', 'sand'],\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor': ['cement', 'sand', 'circuit pipe', 'Cpvc', '&Pvc pipe'],\n",
        "    '5th floor Columns casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    '5th Floor slab casting': ['TMT bar', 'cement', 'sand', 'aggregates', 'Pvc pipes', 'circuit pipes', 'lightbox', 'fan box'],\n",
        "    'Brick work of 3rd to 5th Floor': ['blocks/bricks', 'cement', 'sand'],\n",
        "    'Electrical concealed, PVC Fitting, plastering at 2nd-5th floor': ['cement', 'sand', 'circuit pipe', 'Cpvc', '&Pvc pipe'],\n",
        "    'Plastering on outer sides': ['cement', 'sand'],\n",
        "    'Tiles work': ['Tiles'],\n",
        "    'Painting and Finishing': ['paint', 'putty', 'primer'],\n",
        "    'Plumbing & Sanitary,Electrification Works': ['Wire', 'switch', 'nozzle Bib cock', 'shower', 'kitchen accessories', 'lights', 'fans', 'sheets', 'basin', 'sink', 'etc.'],\n",
        "    'Doors & Windows Fixing Furniture work': ['Furniture', 'hardware', 'glass']\n",
        "}\n",
        "\n",
        "\n",
        "# Initialize empty lists to store relevant_stage and relevant_columns\n",
        "relevant_stage_list = []\n",
        "relevant_columns_list = []\n",
        "\n",
        "# Iterate through each row (project) in new_data\n",
        "for index, row in new_data.iterrows():\n",
        "    days_elapsed = (current_date - row['actual_commencement_date']).days\n",
        "    total_days = row['total_days']\n",
        "\n",
        "    relevant_stage = None\n",
        "    relevant_columns = []\n",
        "\n",
        "    for stage in stage_columns:\n",
        "\n",
        "        if total_days is None or np.isnan(total_days):\n",
        "            # Set relevant_stage and relevant_columns to None if total_days is missing\n",
        "            relevant_stage = None\n",
        "            relevant_columns = []\n",
        "            break\n",
        "\n",
        "        stage_duration = row[stage]\n",
        "        total_days -= stage_duration\n",
        "\n",
        "        if total_days <= days_elapsed:\n",
        "            relevant_stage = stage\n",
        "            relevant_columns = [stage for stage in stage_columns[stage_columns.index(stage):]]\n",
        "            break\n",
        "\n",
        "    relevant_stage_list.append(relevant_stage)\n",
        "    relevant_columns_list.append(relevant_columns)\n",
        "\n",
        "    # Add the 'relevant_stage' and 'relevant_columns' columns to the new_data DataFrame\n",
        "new_data['relevant_stage'] = relevant_stage_list\n",
        "new_data['relevant_columns'] = relevant_columns_list\n",
        "\n",
        "\n",
        "# Initialize empty DataFrame to store adjusted days data\n",
        "adjusted_days_data = pd.DataFrame(columns=stage_columns)\n",
        "\n",
        "# Iterate through each row (project) in new_data\n",
        "for index, row in new_data.iterrows():\n",
        "    current_stage = row['current_stage']\n",
        "    relevant_columns = row['relevant_columns']\n",
        "\n",
        "    if current_stage == 'completed':\n",
        "        # For completed projects, set 'days' to NaN for all stage columns\n",
        "        days_values = [np.nan] * len(stage_columns)\n",
        "    elif current_stage == 'running':\n",
        "        # For running projects, update 'days' based on relevant_columns\n",
        "        days_values = [row[stage] if stage in relevant_columns else np.nan for stage in stage_columns]\n",
        "    elif current_stage == 'upcoming':\n",
        "        # For upcoming projects, keep the predicted 'days' values\n",
        "        days_values = [row[stage] for stage in stage_columns]\n",
        "\n",
        "    # Append the days_values to the adjusted_days_data\n",
        "    adjusted_days_data = adjusted_days_data.append(pd.Series(days_values, index=stage_columns), ignore_index=True)\n",
        "\n",
        "\n",
        "# Replace the original stage values in new_data with adjusted values\n",
        "new_data[stage_columns] = adjusted_days_data\n",
        "\n",
        "# Create a list to store the data\n",
        "data = []\n",
        "\n",
        "# Iterate through each row (project) in the new_data DataFrame\n",
        "for index, row in new_data.iterrows():\n",
        "    current_materials = []  # List to store materials for the current stage\n",
        "    current_stage_start_date = current_date  # Initialize with the current date\n",
        "    project_id = f'Project_{index + 1}'  # Generate a project_id\n",
        "\n",
        "    for stage in stage_columns:\n",
        "        stage_duration = row[stage]\n",
        "\n",
        "        if not pd.isna(stage_duration):\n",
        "            # Calculate the stage end date\n",
        "            stage_end_date = current_stage_start_date + pd.Timedelta(days=stage_duration)\n",
        "\n",
        "            # Format the dates for display\n",
        "            start_date_str = current_stage_start_date.strftime('%m/%d/%Y')\n",
        "            end_date_str = stage_end_date.strftime('%m/%d/%Y')\n",
        "\n",
        "            # Check if there are materials for this stage\n",
        "            materials = stage_materials.get(stage, [])\n",
        "\n",
        "            if materials:\n",
        "                # Store the data in the desired format\n",
        "                data.append([end_date_str, stage, \", \".join(materials), project_id, row['organisation_name'], row['office_no'], row['project_res_no']])\n",
        "\n",
        "            # Update the start date for the next stage\n",
        "            current_stage_start_date = stage_end_date\n",
        "\n",
        "# Create a DataFrame from the data\n",
        "output_data = pd.DataFrame(data, columns=['Date', 'Stage', 'Recommended Materials', 'Project_ID', 'organisation_name', 'office_no', 'project_res_no'])\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "output_data.to_csv('output_5_final.csv', index=False)\n"
      ],
      "metadata": {
        "id": "EosRQPuC15fF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}